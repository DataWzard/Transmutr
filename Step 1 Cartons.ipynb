{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282e7aea-3d51-4990-babc-2edb88a01f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas tqdm openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84476c09-e49b-49b2-ae2c-d71efe963256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from openpyxl import load_workbook, Workbook\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.styles import Font\n",
    "from openpyxl.styles import NamedStyle\n",
    "\n",
    "# Decorator to measure execution time\n",
    "def time_complexity(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        print(f\"Function '{func.__name__}' took {end_time - start_time:.2f} seconds to execute.\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "# Column rename mapping\n",
    "column_mapping = {\n",
    "    \"fulfillment_id\": \"orderId\",\n",
    "    \"ref_id\": \"refId\",\n",
    "    \"index\": \"index\",\n",
    "    \"name\": \"name\",\n",
    "    \"dimensions\": \"dimensions\",\n",
    "    \"cost\": \"Price\",\n",
    "    \"base_cost\": \"base_cost\",\n",
    "    \"total_volume\": \"Carton_volume\",\n",
    "    \"net_volume\": \"Order_volume\",\n",
    "    \"volume_utilization\": \"volume_utilization\",\n",
    "    \"surface_area\": \"surface_area\",\n",
    "    \"total_weight\": \"total_weight\",\n",
    "    \"net_weight\": \"net_weight\",\n",
    "    \"tare_weight\": \"tare_weight\",\n",
    "    \"weight_utilization\": \"weight_utilization\",\n",
    "    \"item_count\": \"item_count\",\n",
    "    \"dim_weight\": \"dim_weight\",\n",
    "}\n",
    "\n",
    "# Columns for consolidated output\n",
    "consolidated_columns = [\n",
    "    \"orderId\", \"refId\", \"index\", \"name\", \"dimensions\", \"Price\", \"base_cost\",\n",
    "    \"Carton_volume\", \"Order_volume\", \"volume_utilization\", \"surface_area\",\n",
    "    \"total_weight\", \"net_weight\", \"tare_weight\", \"weight_utilization\",\n",
    "    \"dim_weight\", \"item_count\", \"source_flag\"\n",
    "]\n",
    "\n",
    "# Combined sheet column order\n",
    "combined_columns = [\n",
    "    \"orderId_baseline\", \"orderId\", \"refId_baseline\", \"refId\",\n",
    "    \"index_baseline\", \"index\", \"name_baseline\", \"name\",\n",
    "    \"dimensions_baseline\", \"dimensions\", \"Price_baseline\", \"Price\", \"Price_Diff\",\n",
    "    \"base_cost_baseline\", \"base_cost\", \"Carton_volume_baseline\", \"Carton_volume\", \"Carton_volume_Diff\",\n",
    "    \"Order_volume_baseline\", \"Order_volume\", \"Order_volume_Diff\", \"volume_utilization_baseline\", \"volume_utilization\", \n",
    "    \"volume_utilization_Diff\", \"surface_area_baseline\", \"surface_area\", \"total_weight_baseline\", \"total_weight\", \"total_weight_Diff\",\n",
    "    \"net_weight_baseline\", \"net_weight\", \"tare_weight_baseline\", \"tare_weight\",\n",
    "    \"weight_utilization_baseline\", \"weight_utilization\", \"dim_weight_baseline\", \"dim_weight\",\n",
    "    \"item_count_baseline\", \"item_count\", \"Item_Diff\"\n",
    "]\n",
    "\n",
    " # Columns to drop to save memory\n",
    "columns_to_drop = [\"item_summary\"]  \n",
    "\n",
    "# Refined suffix extraction: After \"pacsimulate_####_\", capture the rest of the string\n",
    "def refine_suffix(filename):\n",
    "    \"\"\"Extracts suffix between '_2441.' and next period/end\"\"\"\n",
    "    match = re.search(r\"pacsimulate_(\\d+)\\.(.*?)(?:$|\\.)\", filename)\n",
    "    if match:\n",
    "        return match.group(2)\n",
    "    return None\n",
    "\n",
    "@time_complexity\n",
    "# Loads a file in chunks, processes it, and returns a DataFrame\n",
    "def load_and_process_file_in_chunks(file_path, chunk_size=100000):\n",
    "    try:\n",
    "        chunks = []\n",
    "        for chunk in pd.read_csv(\n",
    "            file_path, delimiter='|', low_memory=False, memory_map=True,\n",
    "            on_bad_lines='skip', chunksize=chunk_size\n",
    "        ):\n",
    "            # Drop unnecessary columns\n",
    "            if columns_to_drop:\n",
    "                chunk = chunk.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "            # Rename columns based on mapping\n",
    "            chunk = chunk.rename(columns={col: column_mapping[col] for col in column_mapping if col in chunk.columns})\n",
    "\n",
    "            # Extract the source_flag using the filename suffix\n",
    "            suffix = refine_suffix(file_path)\n",
    "            if suffix:\n",
    "                chunk[\"source_flag\"] = suffix\n",
    "            else:\n",
    "                print(f\"Warning: No valid suffix in file {file_path}.\")\n",
    "\n",
    "            # Reindex to ensure all required columns are present\n",
    "            chunk = chunk.reindex(columns=consolidated_columns, fill_value=None)\n",
    "\n",
    "            chunks.append(chunk)\n",
    "\n",
    "        return pd.concat(chunks, ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load file {file_path}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def calculate_consolidated_fields(df):\n",
    "    # Calculate Dimmed\n",
    "    df['Dimmed'] = np.where(df['dim_weight'] > df['total_weight'], 'Yes', 'No')\n",
    "\n",
    "    # Calculate Billed Weight\n",
    "    df['Billed_Weight'] = np.where(df['dim_weight'] > df['total_weight'], np.ceil(df['dim_weight']), np.ceil(df['total_weight'])).astype(int)\n",
    "    \n",
    "    # Billed Over Actual\n",
    "    df['total_weight'] = np.ceil(df['total_weight'])\n",
    "\n",
    "    # Then calculate the 'Billed_over_Actual' column\n",
    "    df['Billed_over_Actual'] = np.where(df['Billed_Weight'] - df['total_weight'] > 0, df['Billed_Weight'] - df['total_weight'], 0)\n",
    "\n",
    "    # Split dimensions into L, W, H\n",
    "    dimensions_split = df['dimensions'].str.split(',', expand=True)\n",
    "    \n",
    "    # Validate that the split resulted in exactly three parts\n",
    "    if dimensions_split.shape[1] != 3:\n",
    "        print(\"Warning: 'dimensions' column does not split into exactly three parts (L,W,H). Filling with NaN.\")\n",
    "        dimensions_split = dimensions_split.reindex(columns=[0,1,2], fill_value=np.nan)\n",
    "\n",
    "    # Assign to new columns\n",
    "    df['L'] = pd.to_numeric(dimensions_split[0].str.strip(), errors='coerce')\n",
    "    df['W'] = pd.to_numeric(dimensions_split[1].str.strip(), errors='coerce')\n",
    "    df['H'] = pd.to_numeric(dimensions_split[2].str.strip(), errors='coerce')\n",
    "\n",
    "    # Calculate Surface Area (SA)\n",
    "    #df['SA'] = 2 * (df['L'] * df['W'] + df['L'] * df['H'] + df['W'] * df['H']) + 2 * (df['W'] ** 2)\n",
    "\n",
    "    return df\n",
    "\n",
    "@time_complexity\n",
    "def compute_differences(df):\n",
    "    try:\n",
    "        # Define the column pairs for differences\n",
    "        column_pairs = [\n",
    "            (\"Price_baseline\", \"Price\", \"Price_Diff\"),\n",
    "            (\"Order_volume_baseline\", \"Order_volume\", \"Order_volume_Diff\"),\n",
    "            (\"item_count_baseline\", \"item_count\", \"Item_Diff\"),\n",
    "            (\"Carton_volume_baseline\", \"Carton_volume\", \"Carton_volume_Diff\"),\n",
    "            (\"volume_utilization_baseline\", \"volume_utilization\", \"volume_utilization_Diff\"),\n",
    "            (\"total_weight_baseline\", \"total_weight\", \"total_weight_Diff\"),\n",
    "        ]\n",
    "\n",
    "        for col_baseline, col, col_diff in tqdm(\n",
    "            column_pairs, desc=\"Computing Differences\", unit=\"file\", colour=\"green\"\n",
    "        ):\n",
    "            if col_baseline in df.columns and col in df.columns:\n",
    "                df[col_baseline] = pd.to_numeric(df[col_baseline], errors=\"coerce\").fillna(0)\n",
    "                df[col] = pd.to_numeric(df[col], errors=\"coerce\").fillna(0)\n",
    "                df[col_diff] = df[col] - df[col_baseline]\n",
    "            else:\n",
    "                print(f\"Skipping difference calculation for {col_diff}: Missing {col_baseline} or {col}\")\n",
    "\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error in compute_differences: {e}\")\n",
    "        return df\n",
    "\n",
    "def apply_dynamic_column_formats(sheet):\n",
    "    \n",
    "    number_style = NamedStyle(name=\"number\")\n",
    "    number_style.number_format = '0.00'  \n",
    "    \n",
    "    percentage_style = NamedStyle(name=\"percentage\")\n",
    "    percentage_style.number_format = '0.00%' \n",
    "\n",
    "    numeric_columns = [\n",
    "        \"Price_baseline\", \"Price\", \"Price_Diff\", \n",
    "        \"Carton_volume_baseline\", \"Carton_volume\", \"Carton_volume_Diff\", \n",
    "        \"Order_volume_baseline\", \"Order_volume\", \"Order_volume_Diff\", \n",
    "        \"surface_area_baseline\", \"surface_area\", \n",
    "        \"dim_weight_baseline\", \"dim_weight\"\n",
    "    ]\n",
    "    utilization_columns = [\n",
    "        \"volume_utilization_baseline\", \"volume_utilization\", \"volume_utilization_Diff\", \n",
    "        \"weight_utilization_baseline\", \"weight_utilization\"\n",
    "    ]\n",
    "\n",
    "    # Loop through columns and apply styles based on column name\n",
    "    for col in sheet.columns:\n",
    "        column_letter = col[0].column_letter\n",
    "        column_name = str(col[0].value).strip() if col[0].value else \"\"\n",
    "\n",
    "        # Apply number format to numeric columns\n",
    "        if column_name in numeric_columns:\n",
    "            for cell in col:\n",
    "                cell.number_format = '0.00'  \n",
    "        \n",
    "        elif column_name in utilization_columns:\n",
    "            for cell in col:\n",
    "                cell.number_format = '0.00%'  \n",
    "\n",
    "@time_complexity\n",
    "def process_files(directory, output_directory):\n",
    "    files = os.listdir(directory)\n",
    "    data_frames = {}\n",
    "    consolidated_data = []\n",
    "    baseline_file = None\n",
    "\n",
    "    # Identify the baseline file\n",
    "    for filename in files:\n",
    "        if \"baseline\" in filename.lower():\n",
    "            baseline_file = filename\n",
    "            break\n",
    "\n",
    "    if not baseline_file:\n",
    "        raise ValueError(\"Baseline file not found. Ensure a file containing 'baseline' in its name exists.\")\n",
    "\n",
    "    # Process files\n",
    "    with tqdm(total=len(files), desc=\"Loading files\", unit=\"file\", colour=\"blue\") as pbar:\n",
    "        for filename in files:\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            df = load_and_process_file_in_chunks(file_path, chunk_size=100000)\n",
    "            if not df.empty:\n",
    "                data_frames[filename] = df\n",
    "                consolidated_data.append(df)\n",
    "            else:\n",
    "                print(f\"Warning: No valid data in file {filename}\")\n",
    "            pbar.update(n=1)\n",
    "            \n",
    "\n",
    "\n",
    "    # Consolidate all data into a single DataFrame\n",
    "    if consolidated_data:\n",
    "        consolidated_output = pd.concat(consolidated_data, ignore_index=True)\n",
    "        try:\n",
    "            # Perform any calculations \n",
    "            consolidated_output = calculate_consolidated_fields(consolidated_output)\n",
    "            \n",
    "            # Save the consolidated output\n",
    "            consolidated_output_path = os.path.join(output_directory, \"consolidated_output.xlsx\")\n",
    "            with pd.ExcelWriter(consolidated_output_path, engine='openpyxl') as writer:\n",
    "                consolidated_output.to_excel(writer, sheet_name=\"Consolidated_Output\", index=False)\n",
    "\n",
    "                workbook = writer.book\n",
    "                sheet = writer.sheets[\"Consolidated_Output\"]\n",
    "                \n",
    "                \n",
    "                # Header formating \n",
    "                for cell in sheet[1]:\n",
    "                    cell.font = Font(bold=False)\n",
    "                # column formatting\n",
    "                for col in sheet.columns:\n",
    "                    column_letter = col[0].column_letter\n",
    "                    # Get the maximum length of the column header and its values\n",
    "                    header_length = len(str(col[0].value)) if col[0].value else 0\n",
    "                    # Calculate the column width\n",
    "                    column_width = max(header_length + 0.5, 13)\n",
    "                    # Set the column width\n",
    "                    sheet.column_dimensions[column_letter].width = column_width\n",
    "\n",
    "            print(f\"Consolidated output saved at: {consolidated_output_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during consolidated calculations or saving: {e}\")\n",
    "    else:\n",
    "        print(\"No data to consolidate.\")\n",
    "\n",
    "    # Define the new output file name\n",
    "    comparison_filename = \"combined_output.xlsx\"\n",
    "    comparison_path = os.path.join(output_directory, comparison_filename)\n",
    "    \n",
    "    # Save comparison outputs to Excel\n",
    "    baseline_df = data_frames.pop(baseline_file)\n",
    "    with pd.ExcelWriter(comparison_path, engine='openpyxl') as writer:\n",
    "        for key, df in data_frames.items():\n",
    "            sheet_name = refine_suffix(key)  # Using the refined filename as sheet name\n",
    "            if not sheet_name:\n",
    "                print(f\"Skipping sheet for file {key} due to invalid suffix.\")\n",
    "                continue  # Skip empty suffix\n",
    "            \n",
    "            # Align comparison DataFrame columns with combined_columns\n",
    "            comparison_df = df.reindex(columns=[col.replace(\"_baseline\", \"\") for col in combined_columns if \"_baseline\" not in col])\n",
    "\n",
    "            # Combine baseline and comparison data\n",
    "            combined_df = pd.concat(\n",
    "                [baseline_df.add_suffix(\"_baseline\"), comparison_df],\n",
    "                axis=1\n",
    "            ).reindex(columns=combined_columns)\n",
    "\n",
    "            # Compute differences\n",
    "            combined_df = compute_differences(combined_df)\n",
    "\n",
    "            # Keep the difference columns\n",
    "            difference_columns = [\n",
    "                \"Price_Diff\", \"Order_volume_Diff\", \"Item_Diff\", \n",
    "                \"Carton_volume_Diff\", \"volume_utilization_Diff\", \"total_weight_Diff\"\n",
    "            ]\n",
    "\n",
    "            if combined_df.empty:\n",
    "                print(f\"Warning: Sheet {sheet_name} has no data. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Write the combined DataFrame to the corresponding sheet\n",
    "            combined_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "            # Apply formulas for Dimmed and Billed Weight\n",
    "            workbook = writer.book\n",
    "            sheet = writer.sheets[sheet_name]\n",
    "\n",
    "            # Apply dynamic formatting\n",
    "            apply_dynamic_column_formats(sheet)\n",
    "\n",
    "            # Header formating \n",
    "            for cell in sheet[1]:\n",
    "                cell.font = Font(bold=False)\n",
    "\n",
    "            # Column width adjustments\n",
    "            for col in sheet.columns:\n",
    "                column_letter = col[0].column_letter\n",
    "                header_length = len(str(col[0].value)) if col[0].value else 0\n",
    "                column_width = max(header_length + 0.5, 13)\n",
    "                sheet.column_dimensions[column_letter].width = column_width\n",
    "\n",
    "            headers = [str(cell.value).strip() for cell in sheet[1]]\n",
    "            dim_weight_col_idx = next((i + 1 for i, h in enumerate(headers) if h.startswith(\"dim_weight_\")), None)\n",
    "            total_weight_col_idx = next((i + 1 for i, h in enumerate(headers) if h.startswith(\"total_weight_\")), None)\n",
    "\n",
    "            if dim_weight_col_idx is None or total_weight_col_idx is None:\n",
    "                print(f\"Warning: Required columns for Dimmed and Billed Weight formulas not found in '{sheet_name}'. Headers: {headers}\")\n",
    "                continue\n",
    "\n",
    "            last_column = len(headers)\n",
    "            dimmed_col_letter = get_column_letter(last_column + 1)\n",
    "            billed_weight_col_letter = get_column_letter(last_column + 2)\n",
    "\n",
    "            sheet[f\"{dimmed_col_letter}1\"] = \"Dimmed\"\n",
    "            sheet[f\"{billed_weight_col_letter}1\"] = \"Billed_Weight\"\n",
    "\n",
    "            for row in range(2, sheet.max_row + 1):\n",
    "                sheet[f\"{dimmed_col_letter}{row}\"] = (\n",
    "                    f\"=IF({get_column_letter(dim_weight_col_idx)}{row} > {get_column_letter(total_weight_col_idx)}{row}, \\\"Yes\\\", \\\"No\\\")\"\n",
    "                )\n",
    "                sheet[f\"{billed_weight_col_letter}{row}\"] = (\n",
    "                    f\"=IF({get_column_letter(dim_weight_col_idx)}{row} > {get_column_letter(total_weight_col_idx)}{row}, \"\n",
    "                    f\"ROUNDUP({get_column_letter(dim_weight_col_idx)}{row}, 0), ROUNDUP({get_column_letter(total_weight_col_idx)}{row}, 0))\"\n",
    "                )\n",
    "\n",
    "            final_df = combined_df[difference_columns]\n",
    "            \n",
    "    print(f\"Comparison Excel saved at {comparison_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    directory = \"Upload Path\"\n",
    "    output_directory = \"Output Path\"\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    process_files(directory, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c132ad3c-223e-43cd-a98e-c341022529e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def refine_suffix(filename):\n",
    "\n",
    "    match = re.search(r\"pacsimulate_(\\d+)\\.(.*?)(?:$|\\.)\", filename)\n",
    "    if match:\n",
    "        return match.group(2)\n",
    "    return None\n",
    "\n",
    "# Test\n",
    "print(refine_suffix(\"pacsimulate_2441.baseline.output_cartons\")) \n",
    "print(refine_suffix(\"pacsimulate_2441.opc_top-14.output_cartons\"))\n",
    "print(refine_suffix(\"pacsimulate_2441.pacapi.output_cartons\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
