{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd712f0-0e04-4500-97d9-830ca4e7e62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas tqdm openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecc3867-79bd-467b-b0ad-680f1c244018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from openpyxl import load_workbook, Workbook\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.styles import Font\n",
    "from openpyxl.styles import NamedStyle\n",
    "\n",
    "def time_complexity(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f\"Function '{func.__name__}' took {elapsed_time:.2f} seconds to execute.\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "column_mapping = {\n",
    "    \"fulfillment_id\": \"orderId\",\n",
    "    \"value\": \"Price\",\n",
    "    \"optimized_cartons\": \"Carton_Count\",\n",
    "    \"total_volume\": \"Carton_volume\",\n",
    "    \"net_volume\": \"Order_volume\",\n",
    "    \"items_total\": \"items_total\",\n",
    "    \"items_leftover\": \"items_leftover\",\n",
    "    \"volume_utilization\": \"volume_utilization\",\n",
    "    \"total_weight\": \"total_weight\",\n",
    "    \"box_counts\": \"box_counts\",\n",
    "    \"surface_area\": \"surface_area\",\n",
    "    \"weight_utilization\": \"weight_utilization\",\n",
    "    \"net_weight\": \"net_weight\",\n",
    "    \"tare_weight\": \"tare_weight\"\n",
    "}\n",
    "\n",
    "# Columns for consolidated output\n",
    "consolidated_columns = [\n",
    "    \"orderId\", \"Price\", \"Carton_Count\", \"Carton_volume\", \"Order_volume\",\n",
    "    \"items_total\", \"items_leftover\",\"volume_utilization\", \"total_weight\", \n",
    "    \"box_counts\", \"surface_area\", \"weight_utilization\", \"net_weight\",\n",
    "    \"tare_weight\", \"source_flag\"\n",
    "]\n",
    "\n",
    "combined_columns = [\n",
    "    \"orderId_baseline\", \"orderId\", \n",
    "    \"Price_baseline\", \"Price\", \"Price_Diff\",\n",
    "    \"Carton_Count_baseline\", \"Carton_Count\", \n",
    "    \"Carton_volume_baseline\", \"Carton_volume\", \"Carton_Volume_Diff\",\n",
    "    \"Order_volume_baseline\", \"Order_volume\", \"Order_Volume_Diff\",\n",
    "    \"items_total_baseline\", \"items_total\", \n",
    "    \"items_leftover_baseline\", \"items_leftover\",\"items_leftover_Diff\",\n",
    "    \"volume_utilization_baseline\", \"volume_utilization\", \"volume_utilization_Diff\", \n",
    "    \"total_weight_baseline\", \"total_weight\", \"total_weight_Diff\",\n",
    "    \"box_counts_baseline\", \"box_counts\", \"box_counts_Diff\",\n",
    "    \"surface_area_baseline\", \"surface_area\", \n",
    "    \"weight_utilization_baseline\", \"weight_utilization\",\n",
    "    \"net_weight_baseline\", \"net_weight\", \"tare_weight_baseline\", \"tare_weight\"\n",
    "]\n",
    "\n",
    "columns_to_drop = [\n",
    "    \"all_packed\", \"dim_rated\", \"zone\", \"original_price\",\n",
    "    \"optimized_price\", \"box_summary\", \"total_time\", \"item_sets\", \"pack_request\", \"pack_response\"\n",
    "]\n",
    "\n",
    "# Refined suffix extraction: After \"pacsimulate_####_\", capture the rest of the string\n",
    "def refine_suffix(filename):\n",
    "    \"\"\"Extracts suffix between '_2441.' and next period/end\"\"\"\n",
    "    match = re.search(r\"pacsimulate_(\\d+)\\.(.*?)(?:$|\\.)\", filename)\n",
    "    if match:\n",
    "        return match.group(2)\n",
    "    return None\n",
    "\n",
    "@time_complexity\n",
    "# Loads a file in chunks, processes it, and returns a DataFrame\n",
    "def load_and_process_file_in_chunks(file_path, chunk_size=100000):\n",
    "    try:\n",
    "        chunks = []\n",
    "        for chunk in pd.read_csv(\n",
    "            file_path, delimiter='|', low_memory=False, memory_map=True,\n",
    "            on_bad_lines='skip', chunksize=chunk_size\n",
    "        ):\n",
    "            # Drop unnecessary columns\n",
    "            if columns_to_drop:\n",
    "                chunk = chunk.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "            # Rename columns based on mapping\n",
    "            chunk = chunk.rename(columns={col: column_mapping[col] for col in column_mapping if col in chunk.columns})\n",
    "\n",
    "            # Extract the source_flag using the filename suffix\n",
    "            suffix = refine_suffix(file_path)\n",
    "            if suffix:\n",
    "                chunk[\"source_flag\"] = suffix\n",
    "            else:\n",
    "                print(f\"Warning: No valid suffix in file {file_path}.\")\n",
    "\n",
    "            # Reindex to ensure all required columns are present\n",
    "            chunk = chunk.reindex(columns=consolidated_columns, fill_value=None)\n",
    "\n",
    "            chunks.append(chunk)\n",
    "\n",
    "        return pd.concat(chunks, ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load file {file_path}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "@time_complexity\n",
    "def compute_differences(df):\n",
    "    try:\n",
    "        # Define the column pairs for differences\n",
    "        column_pairs = [\n",
    "            (\"Price_baseline\", \"Price\", \"Price_Diff\"),\n",
    "            (\"Carton_volume_baseline\", \"Carton_volume\", \"Carton_Volume_Diff\"),\n",
    "            (\"Order_volume_baseline\", \"Order_volume\", \"Order_Volume_Diff\"),\n",
    "            (\"items_leftover_baseline\", \"items_leftover\",\"items_leftover_Diff\"),  \n",
    "            (\"volume_utilization_baseline\", \"volume_utilization\", \"volume_utilization_Diff\"),\n",
    "            (\"total_weight_baseline\", \"total_weight\", \"total_weight_Diff\"),\n",
    "            (\"box_counts_baseline\", \"box_counts\", \"box_counts_Diff\"),\n",
    "        ]\n",
    "\n",
    "        for col_baseline, col, col_diff in tqdm(\n",
    "            column_pairs, desc=\"Computing Differences\", unit=\"file\", colour=\"green\"\n",
    "        ):\n",
    "            if col_baseline in df.columns and col in df.columns:\n",
    "                df[col_baseline] = pd.to_numeric(df[col_baseline], errors=\"coerce\").fillna(0)\n",
    "                df[col] = pd.to_numeric(df[col], errors=\"coerce\").fillna(0)\n",
    "                df[col_diff] = df[col] - df[col_baseline]\n",
    "            else:\n",
    "                print(f\"Skipping difference calculation for {col_diff}: Missing {col_baseline} or {col}\")\n",
    "\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error in compute_differences: {e}\")\n",
    "        return df\n",
    "def apply_dynamic_column_formats(sheet):\n",
    "    # Define the number style with 2 decimal places for numeric columns\n",
    "    number_style = NamedStyle(name=\"number\")\n",
    "    number_style.number_format = '0.00'  # Number format for 2 decimal places\n",
    "    \n",
    "    # Define the percentage style for utilization columns\n",
    "    percentage_style = NamedStyle(name=\"percentage\")\n",
    "    percentage_style.number_format = '0.00%'  # Percentage format for utilization columns\n",
    "\n",
    "    # List of columns to apply number formatting (Price, Carton Volume, etc.)\n",
    "    numeric_columns = [\n",
    "        \"Price_baseline\", \"Price\", \"Price_Diff\", \n",
    "        \"Carton_volume_baseline\", \"Carton_volume\", \"Carton_volume_Diff\",\n",
    "        \"box_counts_baseline\", \"box_counts\", \"box_counts_Diff\",\n",
    "        \"Order_volume_baseline\", \"Order_volume\", \"Order_volume_Diff\", \n",
    "        \"total_weight_baseline\", \"total_weight\", \"total_weight_Diff\",\n",
    "        \"net_weight_baseline\", \"net_weight\",\n",
    "        \"surface_area_baseline\", \"surface_area\", \n",
    "        \"dim_weight_baseline\", \"dim_weight\"\n",
    "    ]\n",
    "    \n",
    "    # List of columns for utilization percentage formatting\n",
    "    utilization_columns = [\n",
    "        \"volume_utilization_baseline\", \"volume_utilization\", \"volume_utilization_Diff\", \n",
    "        \"weight_utilization_baseline\", \"weight_utilization\"\n",
    "    ]\n",
    "\n",
    "    # Loop through columns and apply styles based on column name\n",
    "    for col in sheet.columns:\n",
    "        column_letter = col[0].column_letter\n",
    "        column_name = str(col[0].value).strip() if col[0].value else \"\"\n",
    "\n",
    "        # Apply number format to numeric columns\n",
    "        if column_name in numeric_columns:\n",
    "            for cell in col:\n",
    "                cell.number_format = '0.00'  # Apply number format with 2 decimal places\n",
    "        \n",
    "        # Apply percentage format to utilization columns\n",
    "        elif column_name in utilization_columns:\n",
    "            for cell in col:\n",
    "                cell.number_format = '0.00%'  # Apply percentage format\n",
    "\n",
    "@time_complexity\n",
    "def process_files(directory, output_directory):\n",
    "    files = os.listdir(directory)\n",
    "    data_frames = {}\n",
    "    consolidated_data = []\n",
    "    baseline_file = None\n",
    "\n",
    "    # Identify the baseline file\n",
    "    for filename in files:\n",
    "        if \"baseline\" in filename.lower():\n",
    "            baseline_file = filename\n",
    "            break\n",
    "\n",
    "    if not baseline_file:\n",
    "        raise ValueError(\"Baseline file not found. Ensure a file containing 'baseline' in its name exists.\")\n",
    "\n",
    "    # Process files\n",
    "    with tqdm(total=len(files), desc=\"Loading files\", unit=\"file\", colour=\"blue\") as pbar:\n",
    "        for filename in files:\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            df = load_and_process_file_in_chunks(file_path, chunk_size=100000)\n",
    "            if not df.empty:\n",
    "                \n",
    "                data_frames[filename] = df\n",
    "                consolidated_data.append(df)\n",
    "            else:\n",
    "                print(f\"Warning: No valid data in file {filename}\")\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Consolidate all data into a single DataFrame\n",
    "    if consolidated_data:\n",
    "        consolidated_output = pd.concat(consolidated_data, ignore_index=True)\n",
    "        try:\n",
    "                        \n",
    "            # Save the consolidated output\n",
    "            consolidated_output_path = os.path.join(output_directory, \"summary_consolidated_output.xlsx\")\n",
    "            with pd.ExcelWriter(consolidated_output_path, engine='openpyxl') as writer:\n",
    "                consolidated_output.to_excel(writer, sheet_name=\"Consolidated_Output\", index=False)\n",
    "\n",
    "                workbook = writer.book\n",
    "                sheet = writer.sheets[\"Consolidated_Output\"]\n",
    "\n",
    "                # Header formating \n",
    "                for cell in sheet[1]:\n",
    "                    cell.font = Font(bold=False)\n",
    "                # column formatting\n",
    "                for col in sheet.columns:\n",
    "                    column_letter = col[0].column_letter\n",
    "                    # Get the maximum length of the column header and its values\n",
    "                    header_length = len(str(col[0].value)) if col[0].value else 0\n",
    "                    # Calculate the column width\n",
    "                    column_width = max(header_length + 0.5, 13)\n",
    "                    # Set the column width\n",
    "                    sheet.column_dimensions[column_letter].width = column_width\n",
    "\n",
    "            print(f\"Consolidated output saved at: {consolidated_output_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during consolidated calculations or saving: {e}\")\n",
    "    else:\n",
    "        print(\"No data to consolidate.\")\n",
    "\n",
    "    # Extract the run # from the baseline file name\n",
    "    run_match = re.search(r\"pacsimulate_(\\d+)\", baseline_file)\n",
    "    run_number = run_match.group(1)\n",
    "    \n",
    "    # Define the new output file name\n",
    "    comparison_filename = f\"Summary_Output_run_{run_number}.xlsx\"\n",
    "    comparison_path = os.path.join(output_directory, comparison_filename)\n",
    "    \n",
    "    # Save comparison outputs to Excel\n",
    "    baseline_df = data_frames.pop(baseline_file)\n",
    "    with pd.ExcelWriter(comparison_path, engine='openpyxl') as writer:\n",
    "        for key, df in data_frames.items():\n",
    "            sheet_name = refine_suffix(key)  # Using the refined filename as sheet name\n",
    "            if not sheet_name:\n",
    "                print(f\"Skipping sheet for file {key} due to invalid suffix.\")\n",
    "                continue  # Skip empty suffix\n",
    "            \n",
    "            # Align comparison DataFrame columns with combined_columns\n",
    "            comparison_df = df.reindex(columns=[col.replace(\"_baseline\", \"\") for col in combined_columns if \"_baseline\" not in col])\n",
    "\n",
    "            # Combine baseline and comparison data\n",
    "            combined_df = pd.concat(\n",
    "                [baseline_df.add_suffix(\"_baseline\"), comparison_df],\n",
    "                axis=1\n",
    "            ).reindex(columns=combined_columns)\n",
    "\n",
    "            # Compute differences\n",
    "            combined_df = compute_differences(combined_df)\n",
    "\n",
    "            # Keep the difference columns\n",
    "            difference_columns = [\n",
    "                \"Price_Diff\", \"Order_Volume_Diff\", \"Carton_Volume_Diff\",\n",
    "                \"volume_utilization_Diff\", \"total_weight_Diff\", \n",
    "                \"items_leftover_Diff\", \"box_counts_Diff\"\n",
    "            ]\n",
    "\n",
    "            if combined_df.empty:\n",
    "                print(f\"Warning: Sheet {sheet_name} has no data. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Write the combined DataFrame to the corresponding sheet\n",
    "            combined_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "            final_df = combined_df[difference_columns]\n",
    "            \n",
    "            # Apply dynamic formatting\n",
    "            apply_dynamic_column_formats(sheet)\n",
    "\n",
    "            # Header formating \n",
    "            for cell in sheet[1]:\n",
    "                cell.font = Font(bold=False)\n",
    "            # column formatting\n",
    "            for col in sheet.columns:\n",
    "                max_length = 0\n",
    "                column_letter = col[0].column_letter  \n",
    "\n",
    "            for col in sheet.columns:\n",
    "                column_letter = col[0].column_letter\n",
    "                #  Get the maximum length of the column header and its values\n",
    "                header_length = len(str(col[0].value)) if col[0].value else 0\n",
    "                # Calculate the column width\n",
    "                column_width = max(header_length + 0.5, 13)\n",
    "                # Set the column width\n",
    "                sheet.column_dimensions[column_letter].width = column_width\n",
    "\n",
    "    print(f\"Comparison Excel saved at {comparison_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    directory = \"Upload Path\"\n",
    "    output_directory = \"Output Path\"\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    process_files(directory, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bde3a3-3bf8-4c5d-af30-db3304bc48af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
